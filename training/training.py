# -*- coding: utf-8 -*-
"""training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CJ10oYV8j1FjWjBlanoeGoOZ1qgUDACa
"""

from linear_model import OuterBlock2

dropout_rate = 0.3 #by default        
epochs = 10
batch_size = 128 #or 64
Model_DNN = OuterBlock2(embed = 512, dropout_rate = 0.3)

Model_DNN.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3), loss = tf.keras.losses.MeanAbsoluteError())

history = Model_DNN.fit(x = pose2d, y = pose3d, batch_size = batch_size, epochs = 20, validation_split=0.2, shuffle= True)

save_model_dir = "/content/conv_pose"
Model_DNN.save(save_model_dir)
converter = tf.lite.TFLiteConverter.from_saved_model(save_model_dir)
tflite_model = converter.convert()

# Save the model.
with open('/content/conv_pose.tflite', 'wb') as f:
  f.write(tflite_model)

import time 

interpreter = tf.lite.Interpreter(
    model_path = "/content/conv_pose.tflite",
    num_threads=6)
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

input_data = np.float32(pose2d_test[0]).reshape(1,-1)
interpreter.set_tensor(input_details[0]['index'], input_data)

start_time = time.time()
interpreter.invoke()
stop_time = time.time()
print(stop_time - start_time)
output_data = interpreter.get_tensor(output_details[0]['index'])

#Â evaluate 
drive.mount('/content/gdrive')
pred =  Model_DNN.predict(pose2d_test) #data stored in google drive